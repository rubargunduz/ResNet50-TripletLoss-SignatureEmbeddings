{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EcmdmwHpxXRB",
        "outputId": "cef10565-c843-42d8-9c17-47a1ed865b0a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hWQkaJ-uSGLI"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import random\n",
        "from glob import glob\n",
        "\n",
        "def make_triplets(data_dir, num_triplets=10000, seed=42):\n",
        "    random.seed(seed)\n",
        "    people = os.listdir(data_dir)\n",
        "    people = [p for p in people if os.path.isdir(os.path.join(data_dir, p))]\n",
        "\n",
        "    print(\"Number of people: \", len(people))\n",
        "\n",
        "    triplets = []\n",
        "    for _ in range(num_triplets):\n",
        "\n",
        "        # Pick anchor/positive person\n",
        "        person = random.choice(people)\n",
        "        person_path = os.path.join(data_dir, person)\n",
        "\n",
        "        images = glob(os.path.join(person_path, \"*.png\"))\n",
        "        if len(images) < 2:\n",
        "            continue  # skip if not enough images\n",
        "\n",
        "        anchor, positive = random.sample(images, 2)\n",
        "\n",
        "        # Pick negative person\n",
        "        neg_person = random.choice([p for p in people if p != person])\n",
        "        neg_path = os.path.join(data_dir, neg_person)\n",
        "\n",
        "        neg_images = glob(os.path.join(neg_path, \"*.png\"))\n",
        "        if not neg_images:\n",
        "            continue\n",
        "\n",
        "        negative = random.choice(neg_images)\n",
        "        triplets.append((anchor, positive, negative))\n",
        "\n",
        "\n",
        "    return triplets\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IZe9jxD6SNL_",
        "outputId": "ac82d07c-e998-4428-c1ff-aeac3e17a5f7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of people:  56\n",
            "Number of people:  8\n"
          ]
        }
      ],
      "source": [
        "triplets = make_triplets(\"/content/drive/MyDrive/dataset/train\", num_triplets=10000, seed=42)\n",
        "with open(\"triplets.txt\", \"w\") as f:\n",
        "    for a, p, n in triplets:\n",
        "        f.write(f\"{a},{p},{n}\\n\")\n",
        "\n",
        "triplets = make_triplets(\"/content/drive/MyDrive/dataset/test\", num_triplets=2000, seed=5)\n",
        "with open(\"val_triplets.txt\", \"w\") as f:\n",
        "    for a, p, n in triplets:\n",
        "        f.write(f\"{a},{p},{n}\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FKEdKdqpSZSC"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "# Step 1: Binarize with Otsu's threshold\n",
        "def binarize_otsu(image):\n",
        "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "    _, binary = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)\n",
        "    return binary\n",
        "\n",
        "# Step 2: Crop to bounding box of the signature\n",
        "def crop_to_contour(binary_image):\n",
        "    contours, _ = cv2.findContours(binary_image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "    if not contours:\n",
        "        return binary_image  # fallback if no contour\n",
        "    x, y, w, h = cv2.boundingRect(cv2.convexHull(np.vstack(contours)))\n",
        "    cropped = binary_image[y:y+h, x:x+w]\n",
        "    return cropped\n",
        "\n",
        "# Step 3: Pad to square shape (white background)\n",
        "def pad_to_square(img, pad_value=0):\n",
        "    h, w = img.shape[:2]\n",
        "    size = max(h, w)\n",
        "    padded = np.full((size, size), pad_value, dtype=img.dtype)\n",
        "    y_offset = (size - h) // 2\n",
        "    x_offset = (size - w) // 2\n",
        "    padded[y_offset:y_offset+h, x_offset:x_offset+w] = img\n",
        "    return padded\n",
        "\n",
        "# Step 4: Add 25% padding around (white background)\n",
        "def add_border_padding(img, pad_value=0):\n",
        "    h, w = img.shape\n",
        "    pad_h = int(h * 0.25)\n",
        "    pad_w = int(w * 0.25)\n",
        "    padded = cv2.copyMakeBorder(\n",
        "        img, pad_h, pad_h, pad_w, pad_w,\n",
        "        borderType=cv2.BORDER_CONSTANT,\n",
        "        value=pad_value\n",
        "    )\n",
        "    return padded\n",
        "\n",
        "# Step 5: Resize to 224x224\n",
        "def resize_to_target(img, size=(224, 224)):\n",
        "    resized = cv2.resize(img, size, interpolation=cv2.INTER_AREA)\n",
        "    return resized\n",
        "\n",
        "# Step 6: Expand grayscale to 3 channels for ResNet\n",
        "def to_3_channels(img):\n",
        "    return cv2.merge([img, img, img])\n",
        "\n",
        "# 🔄 Full pipeline\n",
        "def preprocess_signature(image_path):\n",
        "    original = cv2.imread(image_path)\n",
        "    binary = binarize_otsu(original)\n",
        "    cropped = crop_to_contour(binary)\n",
        "    squared = pad_to_square(cropped, pad_value=0)  # black background in binary image\n",
        "    extended = add_border_padding(squared, pad_value=0)\n",
        "    resized = resize_to_target(extended)\n",
        "    color = to_3_channels(resized)\n",
        "    normalized = color.astype(np.float32) / 255.0\n",
        "    return normalized\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3n9_Q48ST6y8",
        "outputId": "cbea25e0-6ea6-4d75-ac97-5b4e97cde08b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading triplets...\n",
            "Loaded 6675 triplets.\n",
            "Loaded 2000 triplets.\n",
            "Creating model...\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "\u001b[1m94765736/94765736\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "Compiling model...\n",
            "Starting training...\n",
            "Epoch 1/10\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - loss: 3.8408"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m707s\u001b[0m 6s/step - loss: 3.8225 - val_loss: 5.0000\n",
            "Epoch 2/10\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - loss: 0.3776"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m260s\u001b[0m 3s/step - loss: 0.3771 - val_loss: 4.9977\n",
            "Epoch 3/10\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - loss: 0.4725"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m262s\u001b[0m 3s/step - loss: 0.4717 - val_loss: 1.0684\n",
            "Epoch 4/10\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - loss: 0.3018"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m266s\u001b[0m 3s/step - loss: 0.3015 - val_loss: 0.6104\n",
            "Epoch 5/10\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m263s\u001b[0m 3s/step - loss: 0.1392 - val_loss: 0.7502\n",
            "Epoch 6/10\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - loss: 0.1295"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m205s\u001b[0m 2s/step - loss: 0.1296 - val_loss: 0.4793\n",
            "Epoch 7/10\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m250s\u001b[0m 3s/step - loss: 0.0904 - val_loss: 0.4990\n",
            "Epoch 8/10\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - loss: 0.0808"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m207s\u001b[0m 2s/step - loss: 0.0808 - val_loss: 0.1941\n",
            "Epoch 9/10\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m226s\u001b[0m 2s/step - loss: 0.2111 - val_loss: 0.4783\n",
            "Epoch 10/10\n",
            "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m219s\u001b[0m 2s/step - loss: 0.1297 - val_loss: 1.8527\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving model...\n",
            "Model saved to signature_embedding_model.h5\n",
            "Validation samples:\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "A-P sim: 0.962, A-N sim: 0.838\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "A-P sim: 0.993, A-N sim: 0.506\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n",
            "A-P sim: 0.991, A-N sim: 0.769\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step\n",
            "A-P sim: 0.940, A-N sim: 0.644\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
            "A-P sim: 0.985, A-N sim: 0.737\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import random\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications import ResNet50\n",
        "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Input\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import tensorflow.keras.backend as K\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from tensorflow.keras.layers import Concatenate\n",
        "\n",
        "\n",
        "\n",
        "# ------------------- Config ------------------- #\n",
        "INPUT_SHAPE = (224, 224, 3)\n",
        "EMBEDDING_DIM = 128\n",
        "MARGIN = 5\n",
        "BATCH_SIZE = 32\n",
        "EPOCHS = 10\n",
        "STEPS_PER_EPOCH = 100\n",
        "\n",
        "TRIPLET_PATH = \"/content/triplets.txt\"\n",
        "VAL_TRIPLET_PATH = \"/content/val_triplets.txt\"\n",
        "VALIDATION_STEPS = 20\n",
        "\n",
        "MODEL_SAVE_PATH = \"signature_embedding_model.h5\"\n",
        "\n",
        "\n",
        "# ----------------- Embedding Model ----------------- #\n",
        "def create_embedding_model(input_shape=INPUT_SHAPE, embedding_dim=EMBEDDING_DIM):\n",
        "    base = ResNet50(weights='imagenet', include_top=False, input_shape=input_shape)\n",
        "\n",
        "    \"\"\"\n",
        "    # 🔒 Freeze base layers\n",
        "    for layer in base.layers:\n",
        "        layer.trainable = False\n",
        "\n",
        "    for layer in base.layers[-20:]:\n",
        "        layer.trainable = True\n",
        "    \"\"\"\n",
        "\n",
        "    x = GlobalAveragePooling2D()(base.output)\n",
        "    output = Dense(embedding_dim, activation='linear')(x)\n",
        "\n",
        "    return Model(inputs=base.input, outputs=output)\n",
        "\n",
        "\n",
        "\n",
        "# ----------------- Triplet Model ----------------- #\n",
        "def create_triplet_model(embedding_model):\n",
        "    anchor = Input(shape=INPUT_SHAPE)\n",
        "    positive = Input(shape=INPUT_SHAPE)\n",
        "    negative = Input(shape=INPUT_SHAPE)\n",
        "\n",
        "    emb_anchor = embedding_model(anchor)\n",
        "    emb_positive = embedding_model(positive)\n",
        "    emb_negative = embedding_model(negative)\n",
        "\n",
        "    merged = Concatenate(axis=1)([emb_anchor, emb_positive, emb_negative])\n",
        "    return Model(inputs=[anchor, positive, negative], outputs=merged)\n",
        "\n",
        "\n",
        "# ----------------- Triplet Loss ----------------- #\n",
        "def triplet_loss(margin=MARGIN):\n",
        "    def loss(y_true, y_pred):\n",
        "        # y_pred shape: (batch_size, embedding_dim * 3)\n",
        "        embedding_dim = EMBEDDING_DIM\n",
        "        anchor = y_pred[:, 0:embedding_dim]\n",
        "        positive = y_pred[:, embedding_dim:2*embedding_dim]\n",
        "        negative = y_pred[:, 2*embedding_dim:3*embedding_dim]\n",
        "        pos_dist = K.sum(K.square(anchor - positive), axis=-1)\n",
        "        neg_dist = K.sum(K.square(anchor - negative), axis=-1)\n",
        "        return K.mean(K.maximum(pos_dist - neg_dist + margin, 0.0))\n",
        "    return loss\n",
        "\n",
        "\n",
        "# ----------------- Load Triplets ----------------- #\n",
        "def load_triplets(filepath):\n",
        "    with open(filepath, \"r\") as f:\n",
        "        lines = f.readlines()\n",
        "    triplets = [tuple(line.strip().split(\",\")) for line in lines]\n",
        "    return triplets\n",
        "\n",
        "\n",
        "# ----------------- Data Augmentation ----------------- #\n",
        "augmentor = ImageDataGenerator(\n",
        "    rotation_range=5,\n",
        "    width_shift_range=0.05,\n",
        "    height_shift_range=0.05,\n",
        "    zoom_range=0.05,\n",
        "    fill_mode='nearest'\n",
        ")\n",
        "\n",
        "def load_image(path, augment=False):\n",
        "    img = preprocess_signature(path)  # Preprocessing pipeline\n",
        "    if augment:\n",
        "        img = augmentor.random_transform(img)\n",
        "    return img\n",
        "\n",
        "\n",
        "\n",
        "# ----------------- Triplet Generator ----------------- #\n",
        "def generate_triplet_batch(triplets, batch_size):\n",
        "    while True:\n",
        "        anchor_imgs, positive_imgs, negative_imgs = [], [], []\n",
        "        batch = random.sample(triplets, batch_size)\n",
        "        for a, p, n in batch:\n",
        "            anchor_imgs.append(load_image(a, augment=True))\n",
        "            positive_imgs.append(load_image(p, augment=True))\n",
        "            negative_imgs.append(load_image(n, augment=False))\n",
        "        # Concatenate along axis 0 for batch, axis 1 for embedding\n",
        "        anchors = np.array(anchor_imgs)\n",
        "        positives = np.array(positive_imgs)\n",
        "        negatives = np.array(negative_imgs)\n",
        "        # Keras expects inputs as a tuple and dummy labels\n",
        "        yield (anchors, positives, negatives), np.zeros((batch_size,))\n",
        "\n",
        "def get_triplet_dataset(triplets, batch_size):\n",
        "    output_signature = (\n",
        "        (\n",
        "            tf.TensorSpec(shape=(None, 224, 224, 3), dtype=tf.float32),\n",
        "            tf.TensorSpec(shape=(None, 224, 224, 3), dtype=tf.float32),\n",
        "            tf.TensorSpec(shape=(None, 224, 224, 3), dtype=tf.float32)\n",
        "        ),\n",
        "        tf.TensorSpec(shape=(None,), dtype=tf.float32)\n",
        "    )\n",
        "    return tf.data.Dataset.from_generator(\n",
        "        lambda: generate_triplet_batch(triplets, batch_size),\n",
        "        output_signature=output_signature\n",
        "    )\n",
        "\n",
        "\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def visualize_validation(model, val_triplets, n=5):\n",
        "    samples = random.sample(val_triplets, n)\n",
        "    for a, p, n in samples:\n",
        "        ea = model.predict(np.expand_dims(load_image(a), axis=0))[0]\n",
        "        ep = model.predict(np.expand_dims(load_image(p), axis=0))[0]\n",
        "        en = model.predict(np.expand_dims(load_image(n), axis=0))[0]\n",
        "\n",
        "        sim_pos = cosine_similarity([ea], [ep])[0][0]\n",
        "        sim_neg = cosine_similarity([ea], [en])[0][0]\n",
        "\n",
        "        print(f\"A-P sim: {sim_pos:.3f}, A-N sim: {sim_neg:.3f}\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# ----------------- Main Training ----------------- #\n",
        "def main():\n",
        "    print(\"Loading triplets...\")\n",
        "    triplets = load_triplets(TRIPLET_PATH)\n",
        "    print(f\"Loaded {len(triplets)} triplets.\")\n",
        "\n",
        "    val_triplets = load_triplets(VAL_TRIPLET_PATH)\n",
        "    print(f\"Loaded {len(val_triplets)} triplets.\")\n",
        "\n",
        "    print(\"Creating model...\")\n",
        "    embedding_model = create_embedding_model()\n",
        "    triplet_model = create_triplet_model(embedding_model)\n",
        "\n",
        "    print(\"Compiling model...\")\n",
        "    triplet_model.compile(loss=triplet_loss(), optimizer='adam')\n",
        "\n",
        "    print(\"Starting training...\")\n",
        "\n",
        "\n",
        "    callbacks = [\n",
        "        EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True),\n",
        "        ModelCheckpoint('best_signature_model.h5', monitor='val_loss', save_best_only=True)\n",
        "    ]\n",
        "\n",
        "    # In main(), replace model.fit call:\n",
        "    train_dataset = get_triplet_dataset(triplets, BATCH_SIZE)\n",
        "    val_dataset = get_triplet_dataset(val_triplets, BATCH_SIZE)\n",
        "\n",
        "    triplet_model.fit(\n",
        "        train_dataset,\n",
        "        steps_per_epoch=STEPS_PER_EPOCH,\n",
        "        validation_data=val_dataset,\n",
        "        validation_steps=VALIDATION_STEPS,\n",
        "        epochs=EPOCHS,\n",
        "        callbacks=callbacks\n",
        ")\n",
        "\n",
        "\n",
        "    print(\"Saving model...\")\n",
        "    embedding_model.save(MODEL_SAVE_PATH)\n",
        "    print(f\"Model saved to {MODEL_SAVE_PATH}\")\n",
        "\n",
        "    print(\"Validation samples:\")\n",
        "    visualize_validation(embedding_model, val_triplets)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
